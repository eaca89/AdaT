{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import groupby\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class VideoScene:\n",
    "    def __init__(self, video, stable_duration=1, stable_threshold=0.99, num_unstable=3,\n",
    "                 GESTURE_FOLDER=None, OUTPUT_STABLE_DIR=None, OUTPUT_UNSTABLE_DIR=None):\n",
    "        self.video = video\n",
    "        self.app = self.video.split('/')[-4]\n",
    "        self.trace_no = self.video.split('/')[-3]\n",
    "        self.gifid = self.video.split('/')[-1].replace('.gif', '')\n",
    "        self.GESTURE_FOLDER = GESTURE_FOLDER\n",
    "        self.gesture = self.get_gesture()\n",
    "\n",
    "        self.stable_duration = stable_duration\n",
    "        self.stable_threshold = stable_threshold\n",
    "        self.k_means = num_unstable\n",
    "\n",
    "        self.OUTPUT_STABLE_DIR = OUTPUT_STABLE_DIR\n",
    "        self.OUTPUT_UNSTABLE_DIR = OUTPUT_UNSTABLE_DIR\n",
    "\n",
    "        if len(self.gesture) > 1 or len(self.gesture) == 0:\n",
    "            self.frames, self.y_frames = [], []\n",
    "            self.sim_sequence = []\n",
    "            self.shots = None\n",
    "        else:\n",
    "            self.frames, self.y_frames = self.get_frames_from_video()\n",
    "\n",
    "            # frame difference\n",
    "            self.sim_sequence = self.get_sim_seq()\n",
    "\n",
    "            # group the frames\n",
    "            self.shots = self.detect_shots()\n",
    "\n",
    "    def get_gesture(self):\n",
    "        gesture_file = os.path.join(\n",
    "            self.GESTURE_FOLDER, f'{self.app}/{self.trace_no}/gestures.json')\n",
    "        if not os.path.exists(gesture_file):\n",
    "            return []\n",
    "        with open(gesture_file, 'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "        if self.gifid in data.keys():\n",
    "            gesture = data[self.gifid]\n",
    "        else:\n",
    "            gesture = []\n",
    "        return gesture\n",
    "\n",
    "    def get_frames_from_video(self):\n",
    "        frames = []\n",
    "        y_frames = []\n",
    "        vidcap = cv2.VideoCapture(self.video)\n",
    "        success, frame = vidcap.read()\n",
    "        frames.append(frame)\n",
    "        y_frame = extract_Y(frame)\n",
    "        y_frames.append(y_frame[15:])\n",
    "        while success:\n",
    "            success, frame = vidcap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "            y_frame = extract_Y(frame)\n",
    "            y_frames.append(y_frame[15:])\n",
    "        vidcap.release()\n",
    "\n",
    "        return frames, y_frames\n",
    "\n",
    "    def get_sim_seq(self):\n",
    "        sim_list = [1]\n",
    "        for i in range(0, len(self.y_frames)-1):\n",
    "            sim = ssim(self.y_frames[i], self.y_frames[i+1])\n",
    "            sim_list.append(sim)\n",
    "\n",
    "        return sim_list\n",
    "\n",
    "    def visualize_sim_seq(self):\n",
    "        plt.plot(np.arange(len(self.sim_sequence)),\n",
    "                 np.array(self.sim_sequence))\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_frames(self, i):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(self.frames[i])\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(self.frames[i+1])\n",
    "        plt.axis('off')\n",
    "        # plt.subplot(1, 3, 3)\n",
    "        # plt.imshow(diff)\n",
    "        # plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def is_stable(self, start, end):\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if end > len(self.sim_sequence):\n",
    "            end = len(self.sim_sequence)\n",
    "        return all(x > self.stable_threshold for x in self.sim_sequence[start:end])\n",
    "\n",
    "    def detect_shots(self):\n",
    "        \"\"\"\n",
    "        Detect the shots into stable or transition\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        shots  : [start_idx, end_idx, (-1: stable, 1: transition)]\n",
    "        \"\"\"\n",
    "        stable_list = [self.is_stable(idx-self.stable_duration, idx+self.stable_duration)\n",
    "                       for idx in range(len(self.sim_sequence))]\n",
    "        zipped = zip(stable_list, range(len(stable_list)))\n",
    "\n",
    "        shot_list = []\n",
    "        for k, g in groupby(zipped, lambda x: x[0]):\n",
    "            group_ = list(g).copy()\n",
    "            # Stable\n",
    "            if k:\n",
    "                shot_list.append([group_[0][1], group_[-1][1], -1])\n",
    "            # UnStable\n",
    "            else:\n",
    "                shot_list.append([group_[0][1], group_[-1][1], 1])\n",
    "\n",
    "        assert shot_list[0][0] == 0, \"Shots are not beginning from 0\"\n",
    "        assert shot_list[-1][1] == len(stable_list)-1, \"Shots are not ending\"\n",
    "\n",
    "        return np.array(shot_list)\n",
    "\n",
    "    def get_frames(self):\n",
    "        return self.frames\n",
    "\n",
    "    def get_shots(self):\n",
    "        return self.shots\n",
    "\n",
    "    def write_dataset(self):\n",
    "        if self.shots is None:\n",
    "            return None\n",
    "        for shot in self.shots:\n",
    "            if shot[2] == -1:\n",
    "                selected_idx = math.floor((shot[0]+shot[1]) / 2)\n",
    "                cv2.imwrite(\n",
    "                    f'{self.OUTPUT_STABLE_DIR}/{self.app}-{self.gifid}-{selected_idx}.jpg', self.frames[selected_idx])\n",
    "            else:\n",
    "                unstable_frames = [self.y_frames[i].flatten()\n",
    "                                   for i in range(shot[0], shot[1]+1)]\n",
    "                unstable_frames = np.array(unstable_frames)\n",
    "                kmeans = KMeans(n_clusters=min(self.k_means, unstable_frames.shape[0]),\n",
    "                                init='random', random_state=42)\n",
    "                kmeans.fit(unstable_frames)\n",
    "                Z = kmeans.predict(unstable_frames)\n",
    "                selected_idx = [shot[0]+np.where(Z == i)[0] for i in range(0, min(self.k_means, unstable_frames.shape[0]))\n",
    "                                if len(np.where(Z == i)[0]) > 0]\n",
    "                selected_idx = [interval[0] for interval in selected_idx if len(\n",
    "                    self.frames)-1 not in interval]\n",
    "                for selected in selected_idx:\n",
    "                    cv2.imwrite(\n",
    "                        f'{self.OUTPUT_UNSTABLE_DIR}/{self.app}-{self.gifid}-{selected}.jpg', self.frames[selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Y(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    y, _, _ = cv2.split(img_yuv)\n",
    "    return y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "        Visualize single video\n",
    "    '''\n",
    "    video = '/Rico/animations/com.famousbluemedia.yokee/trace_0/gifs/922.gif'\n",
    "    vs = VideoScene(video)\n",
    "    shots = vs.get_shots()\n",
    "    vs.visualize_sim_seq()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
